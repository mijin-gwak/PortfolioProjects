# Adversarial Text Detection in Korean: Unveiling Elusive Review Techniques

## Overview

Machine learning algorithms often face challenges when dealing with adversarial examples—data subtly modified in a manner almost imperceptible to the human eye. Adversarial texts, specifically in the context of the Korean language, pose unique challenges and opportunities. This project delves into the realm of Korean adversarial text by investigating how reviewers strategically write critical reviews to elude machine translation. The research question guiding this exploration is: "How do Korean reviewers craft critical reviews to evade machine translation?"

## Methods

Korean adversarial texts, often generated by reviewers aiming to write untranslatable content, present a unique landscape due to the distinctive characteristics of the Korean alphabet. Unlike in other languages, Korean reviewers have devised methods that go beyond the typical word or sequence replacement. The project uncovers these methods by analyzing reviews that intentionally hinder translation.

Data for this investigation were collected through Google image searches using the query '한국인만 알아보는 후기 (reviews only Koreans understand).' The resulting screenshots of reviews, now recognized as adversarial examples, serve as the primary dataset. These images were scraped using Python and annotated for analysis using Excel.

## Code

The Python code used for scraping the screenshots and any other relevant code snippets can be found below:

```python
import bs4
import requests
from selenium import webdriver
import os
import time

def download_image(url, folder_name, num):

    # write image to file
    reponse = requests.get(url)
    if reponse.status_code==200:
        with open(os.path.join(folder_name, str(num)+".jpg"), 'wb') as file:
            file.write(reponse.content)


#creating a directory to save images

folder_name = 'images'
if not os.path.isdir(folder_name):
    os.makedirs(folder_name)


chromePath=r'/Users/mijin/Downloads/chromedriver'
driver=webdriver.Chrome(chromePath)

search_URL = "https://www.google.com/search?q=%ED%95%9C%EA%B5%AD%EC%9D%B8%EB%A7%8C+%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94+%ED%9B%84%EA%B8%B0&rlz=1C5CHFA_enKR845KR845&sxsrf=AOaemvIaXvk7J6ru1PGBoz5B9ybBubc78w:1642889136598&source=lnms&tbm=isch&sa=X&ved=2ahUKEwilmpH7rsb1AhXP_KQKHdn4DXoQ_AUoAXoECAEQAw&biw=1440&bih=710&dpr=1"
driver.get(search_URL)

a = input("Waiting for user input to start...")

# Scrolling all the way up
driver.execute_script("window.scrollTo(0, 0);")

page_html = driver.page_source
pageSoup = bs4.BeautifulSoup(page_html, 'html.parser')
containers = pageSoup.findAll('div', {'class':"isv-r PNCib MSM1fd BUooTd"} )

len_containers = len(containers)
print("Found %s images containers"%(len_containers))

len_containers = len(containers)

for i in range(1, len_containers+1):
    if i % 25 == 0:
        continue

    xPath = """//*[@id="islrg"]/div[1]/div[%s]"""%(i)

    previewImageXPath = """//*[@id="islrg"]/div[1]/div[%s]/a[1]/div[1]/img"""%(i)
    previewImageElement = driver.find_element_by_xpath(previewImageXPath)
    previewImageURL = previewImageElement.get_attribute("src")
    #print("preview URL", previewImageURL)


    #print(xPath)


    driver.find_element_by_xpath(xPath).click()
    #time.sleep(3)

    #//*[@id="islrg"]/div[1]/div[16]/a[1]/div[1]/img

    #input('waawgawg another wait')

    # page = driver.page_source
    # soup = bs4.BeautifulSoup(page, 'html.parser')
    # ImgTags = soup.findAll('img', {'class': 'n3VNCb', 'jsname': 'HiaYvf', 'data-noaft': '1'})
    # print("number of the ROI tags", len(ImgTags))
    # link = ImgTags[1].get('src')
    # #print(len(ImgTags))
    # #print(link)
    #
    # n=0
    # for tag in ImgTags:
    #     print(n, tag)
    #     n+=1
    # print(len(ImgTags))

    #/html/body/div[2]/c-wiz/div[3]/div[2]/div[3]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div[1]/a/img

    timeStarted = time.time()
    while True:

        imageElement = driver.find_element_by_xpath("""//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div[1]/a/img""")
        imageURL= imageElement.get_attribute('src')

        if imageURL != previewImageURL:
            #print("actual URL", imageURL)
            break

        else:
            #making a timeout if the full res image can't be loaded
            currentTime = time.time()

            if currentTime - timeStarted > 10:
                print("Timeout! Will download a lower resolution image and move onto the next one")
                break


    #Downloading image
    try:
        download_image(imageURL, folder_name, i)
        print("Downloaded element %s out of %s total. URL: %s" % (i, len_containers + 1, imageURL))
    except:
        print("Couldn't download an image %s, continuing downloading the next one"%(i))

    #//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div[1]/a/img
    #//*[@id="Sva75c"]/div/div/div[3]/div[2]/c-wiz/div/div[1]/div[1]/div[2]/div[1]/a/img
```

## Data Analysis

The annotated data, encompassing a multitude of adversarial text examples, will be presented alongside the scraped screenshots. The analysis involves identifying and categorizing different types of methods employed by Korean reviewers to generate adversarial text. By understanding these evasion techniques, the project aims to contribute insights into the nuances of adversarial text in Korean, providing a foundation for developing more robust language processing algorithms.

## Results

The findings of this project will be showcased through the annotated screenshots and the categorized methods of adversarial text generation. Understanding how reviewers manipulate language to create untranslatable content is crucial for enhancing the resilience of machine translation algorithms, particularly in the Korean context.

## Supplementary Files

[Annotated Excel Data](https://github.com/mijin-gwak/PortfolioProjects/blob/main/Annotation.xlsx)

